{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Verified on VGG clusters.\n",
    "* Used Python 2.7 installation at `/users/ruthfong/anaconda2/`\n",
    "* Using CPU Caffe installation at `export PYTHONPATH=$PYTHONPATH:/users/ruthfong/caffe-1.0/python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "import caffe\n",
    "import torch\n",
    "\n",
    "from utils import get_finetune_model\n",
    "from caffe_transforms import get_caffe_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths.\n",
    "\n",
    "caffe_models_dir = \"/scratch/shared/slow/ruthfong/pointing_game/Jiaming_All_Caffe_Models\"\n",
    "pytorch_models_dir = \"/scratch/shared/slow/ruthfong/pointing_game\"\n",
    "image_dir = \"/users/ruthfong/feature_attribution/images\"\n",
    "\n",
    "img_scale = 224\n",
    "\n",
    "image_path = os.path.join(image_dir, \"doberman.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caffe_model_paths(arch, dataset):\n",
    "    if arch == 'vgg16':\n",
    "        pass\n",
    "    elif arch == 'resnet50':\n",
    "        pass\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    if 'voc' in dataset:\n",
    "        if arch == 'vgg16':\n",
    "            model_dir = os.path.join(caffe_models_dir, 'voc', 'VGG16')\n",
    "            proto_name = 'deploy_fcn.prototxt'\n",
    "            model_name = 'VGG16VOC07.caffemodel'\n",
    "        elif arch == 'resnet50':\n",
    "            model_dir = os.path.join(caffe_models_dir, 'voc', 'ResNet50')\n",
    "            proto_name = 'deploy.prototxt'\n",
    "            model_name = '_iter_230000.caffemodel'\n",
    "        else:\n",
    "            assert False\n",
    "        last_layer = 'fc8-20-conv'\n",
    "    elif 'coco' in dataset:\n",
    "        if arch == 'vgg16':\n",
    "            model_dir = os.path.join(caffe_models_dir, 'coco', 'VGG16')\n",
    "            proto_name = 'deploy_fcn.prototxt'\n",
    "            model_name = 'VGG16COCO.caffemodel'\n",
    "        elif arch == 'resnet50':\n",
    "            model_dir = os.path.join(caffe_models_dir, 'coco', 'ResNet50')\n",
    "            proto_name = 'resnet50-deploy_Jianming.prototxt'\n",
    "            model_name = 'resnet50-coco.caffemodel'\n",
    "        else:\n",
    "            assert False\n",
    "        last_layer = 'fc8-80-conv'\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    return os.path.join(model_dir, proto_name), os.path.join(model_dir, model_name), last_layer\n",
    "\n",
    "\n",
    "def get_ILSVRC_net_transformer(net):\n",
    "    transformer = caffe.io.Transformer({'data':net.blobs['data'].data.shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', np.array([103.939, 116.779, 123.68]))\n",
    "    transformer.set_raw_scale('data', 255)\n",
    "    transformer.set_channel_swap('data', (2,1,0))\n",
    "    return transformer\n",
    "\n",
    "\n",
    "def get_ILSVRC_net_transformer_with_shape(shape):\n",
    "    transformer = caffe.io.Transformer({'data':shape})\n",
    "    transformer.set_transpose('data', (2,0,1))\n",
    "    transformer.set_mean('data', np.array([103.939, 116.779, 123.68]))\n",
    "    transformer.set_raw_scale('data', 255)\n",
    "    transformer.set_channel_swap('data', (2,1,0))\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pytorch_model_path(arch, dataset):\n",
    "    if 'voc' in dataset:\n",
    "        if arch == 'vgg16':\n",
    "            return os.path.join(pytorch_models_dir, 'vgg16_pascal07_Jianming.pth.tar')\n",
    "        elif arch == 'resnet50':\n",
    "            return os.path.join(pytorch_models_dir, 'resnet50_pascal07_Jianming_pytorch.pth.tar')\n",
    "        else:\n",
    "            assert False\n",
    "    elif 'coco' in dataset:\n",
    "        if arch == 'vgg16':\n",
    "            return os.path.join(pytorch_models_dir, 'vgg16_mscoco_Jianming.pth.tar')\n",
    "        elif arch == 'resnet50':\n",
    "            return os.path.join(pytorch_models_dir, 'resnet50_mscoco_Jianming_pytorch.pth.tar')\n",
    "        else:\n",
    "            assert False\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_caffe_output(arch, dataset):\n",
    "    # Initialize caffe model.\n",
    "    proto_path, model_path, last_layer = get_caffe_model_paths(arch=arch, dataset=dataset)\n",
    "    caffe_model = caffe.Net(proto_path, model_path, caffe.TEST)\n",
    "\n",
    "    # Load image.\n",
    "    orig_img = caffe.io.load_image(image_path)\n",
    "    # print(orig_img.shape)\n",
    "\n",
    "    # Resize image.\n",
    "    min_dim = min(orig_img.shape[:2])\n",
    "    new_size = (int(orig_img.shape[0]*img_scale/float(min_dim)), int(orig_img.shape[1]*img_scale/float(min_dim)))\n",
    "    img = resize(orig_img, new_size)\n",
    "    # print(img.shape)\n",
    "\n",
    "    # Change input shape.\n",
    "    caffe_model.blobs['data'].reshape(1, 3, img.shape[0], img.shape[1])\n",
    "\n",
    "    # Get caffe transformer.\n",
    "    transformer = get_ILSVRC_net_transformer_with_shape((1, 3, img.shape[0], img.shape[1]))\n",
    "\n",
    "    # Set input as preprocessed image.\n",
    "    transformed_img = transformer.preprocess('data', img)\n",
    "    caffe_model.blobs['data'].data[...] = transformed_img\n",
    "\n",
    "    # Get output.\n",
    "    out = caffe_model.forward(end=last_layer)\n",
    "    return transformed_img, out\n",
    "\n",
    "\n",
    "def get_pytorch_output(arch, dataset):\n",
    "    # Get PyTorch model.\n",
    "    checkpoint_path = get_pytorch_model_path(arch=arch, dataset=dataset)\n",
    "    pytorch_model = get_finetune_model(arch=arch,\n",
    "                                       dataset=dataset,\n",
    "                                       converted_caffe=True,\n",
    "                                       checkpoint_path=checkpoint_path,\n",
    "                                       convert_to_fully_convolutional=True,\n",
    "                                       final_gap_layer=True)\n",
    "\n",
    "    # Get Caffe transformation.\n",
    "    transform = get_caffe_transform(img_scale)\n",
    "\n",
    "    # Transform image.\n",
    "    orig_img_torch = Image.open(image_path).convert('RGB')\n",
    "    img_torch = transform(orig_img_torch)\n",
    "\n",
    "    # Run network.\n",
    "    out_pytorch = pytorch_model(img_torch.unsqueeze(0))\n",
    "\n",
    "    return img_torch, out_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the equivalency of Caffe and PyTorch models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking vgg16 voc_2007...\n",
      "Correct!\n",
      "\n",
      "Checking vgg16 coco_2014...\n",
      "Correct!\n",
      "\n",
      "Checking resnet50 voc_2007...\n",
      "Correct!\n",
      "\n",
      "Checking resnet50 coco_2014...\n",
      "Correct!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arches = ['vgg16', 'resnet50']\n",
    "datasets = ['voc_2007', 'coco_2014']\n",
    "\n",
    "for arch in arches:\n",
    "    for dataset in datasets:\n",
    "        print('Checking %s %s...' % (arch, dataset))\n",
    "        caffe_img, caffe_out = get_caffe_output(arch, dataset)\n",
    "        pytorch_img, pytorch_out = get_pytorch_output(arch, dataset)\n",
    "\n",
    "        # Check that pre-processed image is the same.\n",
    "        assert np.sum(caffe_img - pytorch_img.numpy()) < 1e-5\n",
    "\n",
    "        # Check that output is nearly the same (looks like small floating point differences).\n",
    "        assert np.mean(caffe_out['fc8'].squeeze() - pytorch_out.data.numpy().squeeze()) < 1e-5\n",
    "        print('Correct!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
